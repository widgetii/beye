/**
 * @namespace   biewlib
 * @file        biewlib/sysdep/ia32/_inlines.h
 * @brief       This file includes 32-bit Intel architecture little inline functions.
 * @version     -
 * @remark      this source file is part of Binary vIEW project (BIEW).
 *              The Binary vIEW (BIEW) is copyright (C) 1995 Nick Kurshev.
 *              All rights reserved. This software is redistributable under the
 *              licence given in the file "Licence.en" ("Licence.ru" in russian
 *              translation) distributed in the BIEW archive.
 * @note        Requires POSIX compatible development system
 *
 * @author      Nick Kurshev
 * @since       2000
 * @note        Development, fixes and improvements
**/
#if !defined(__GNUC__) || !defined(__GNUC_MINOR__) || (__GNUC__ < 2 && __GNUC_MINOR__ < 5) || !defined(NDEBUG)
#include "biewlib/sysdep/generic/_inlines.h"
#else
#ifndef ___INLINES_H
#define ___INLINES_H 1

#define __NEAR__           /**< Obsolete for ia32 platform modifier of near call and data */
#define __FAR__            /**< Obsolete for ia32 platform modifier of far call and data */
#define __HUGE__           /**< Obsolete for ia32 platform modifier of huge pointer */
#define __INTERRUPT__      /**< Impossible for definition with gcc modifier of interrupt call */
#define halloc malloc      /**< For ia32 platform is alias of huge malloc */
#define hrealloc realloc   /**< For ia32 platform is alias of huge realloc */
#define hfree free         /**< For ia32 platform is alias of huge free */
#define HMemCpy memcpy     /**< For ia32 platform is alias of huge memcpy */

#ifdef __EXPERIMENTAL_VERSION
#define __FASTCALL__ __attribute__ (( __regparm__(3) , __stdcall__ )) /**< Fastcall modifier for ia32 */
#else
#define __FASTCALL__ __attribute__ (( __stdcall__ ))                  /**< Fastcall modifier for ia32 */
#endif
#define __NORETURN__ __attribute__ (( __noreturn__ ))                 /**< Noreturn modifier for ia32 */
#define __CONSTFUNC__ __attribute__ (( __const__ ))                   /**< Modifier of contant function for ia32 */
#ifdef __clpusplus
extern "C" {
#endif

#include "biewlib/sysdep/ia32/fastcopy.h"

                /** Changes byte order in 16-bit number */
__inline static tUInt16 __FASTCALL__ __CONSTFUNC__ ByteSwapS(tUInt16 _val)
{
  __asm("xchgb %b0,%h0"	:
        "=q" (_val)	:
        "0" (_val));
    return _val;
}
#define ByteSwapS ByteSwapS

                /** Changes byte order in 32-bit number */
__inline static tUInt32 __FASTCALL__ __CONSTFUNC__ ByteSwapL(tUInt32 _val)
{
#if __CPU__ > 386
 __asm("bswap	%0"	:
      "=r" (_val)       :
#else
 __asm("xchgb	%b0,%h0\n"
      "	rorl	$16,%0\n"
      "	xchgb	%b0,%h0":
      "=q" (_val)	:
#endif
      "0" (_val));
  return _val;
}
#define ByteSwapL ByteSwapL

                /** Changes byte order in 64-bit number */
__inline static tUInt64 __FASTCALL__ __CONSTFUNC__ ByteSwapLL(tUInt64 x)
{
  register union { __extension__ unsigned long long int __ll;
          unsigned long int __l[2]; } __x;
  asm("xchgl	%0,%1":
      "=r"(__x.__l[0]),"=r"(__x.__l[1]):
      "0"(ByteSwapL((tUInt32)x)),"1"(ByteSwapL((tUInt32)(x>>32))));
  return __x.__ll;
}
#define ByteSwapLL ByteSwapLL


#ifndef __BEOS__
                /** Translates byte via table lookup
                  * @return         byte readed from table \e t at offset \e i
                  * @param t        pointer to 256-byte memory block from which will be readed byte
                  * @param i        index of memory block where byte is to be readed
                  * @warning        BEOS can not to process EBX in assembler statements
                **/
__inline static tUInt8 __FASTCALL__ __CONSTFUNC__ __Xlat__(const tUInt8 *_table, tUInt8 _idx)
{
 __asm("xlatb"   :
      "=a" (_idx):
      "0"(_idx),
      "b"(_table));
  return _idx;
}
#define __Xlat__ __Xlat__
#else
#define __Xlat__(t,i) (t[i])
#endif

                /** Compares two 4-byte numbers.
                  * @return         -1 if v1 < v2; +1 if v1 > v2 and 0 if v1 == v2
                  * @param _val1    specified first number to be compared
                  * @param _val2    specified second number to be compared
                  * @note           This implementation does not contain conditional
                                    jump that is being generated by gcc. It is
                                    much better for pipeline stream on modern
                                    processors. refer to: "Intel Architecture
                                    Software Developer's Manual Volume 3: System
                                    Programming" Order Number 243192. Section:
                                    "14.2.3. Eliminating and Reducing the
                                    Number of Branches" and
                                    "14.3. REDUCING PARTIAL REGISTER STALLS ON
                                     P6 FAMILY PROCESSORS".
                **/
__inline static int __FASTCALL__ __CONSTFUNC__ __CmpLong__(tUInt32 _val1, tUInt32 _val2)
{
 register int _ret;
#if __CPU__ > 586
  /* For 2 staging pipeline (PII/Celeron) this code will be ran on 1 CPU cycle
     quicker. For 3 staging (PIII/PPro) it's don't matter. P4 probably has unit
     for instruction reordering and it's don't matter also. */
 __asm("cmpl	%3, %2\n"
      "	seta	%b0\n"
      "	movl	$-1, %2\n"
      "	cmovb	%2, %0":
      "=q"(_ret)       :
      "0"(0),
      "r"(_val1),
      "g"(_val2));
#else
 __asm("cmpl	%3, %2\n"
      "	seta	%b0\n"
      "	sbbl	$0, %0":
      "=q"(_ret)       :
      "0"(0),
      "r"(_val1),
      "g"(_val2));
#endif
 return _ret;
}
#define __CmpLong__ __CmpLong__
                /** Exchanges two bytes in memory.
                  * @return         none
                  * @param _val1    specified pointer to the first byte to be exchanged
                  * @param _val2    specified pointer to the second byte to be exchanged
                  * @note           Main difference from ByteSwap function family -
                                    it is work with different number, rather than
                                    changing byte order within given number.
                 **/
__inline static void __FASTCALL__ __XchgB__(tUInt8 *_val1, tUInt8 *_val2)
{
 register char _tmp;
 __asm("xchgb	%b1,(%2)":
      "=q"(_tmp):
      "0"(*_val2),
      "r"(_val1));
  *_val2 = _tmp;
}
#define __XchgB__ __XchgB__

#ifdef HAVE_MMX
#define REGMM_SIZE 8 /* In the future it can be safety replaced with 16 for SSE2 */

                /** Resets mmx unit.
                  * @return         none
                 **/
__inline static void __FASTCALL__ mmxEmpty( void )
{
  __asm("emms":::"memory");
}
#define __MMX_EMPTY mmxEmpty
                                                       
                /** Performs interleaving of two buffers into destinition one.
                  * @return         none
                  * @param limit    specified size of evenbuffer and oddbuffer
                  * @param destbuffer specified pointer to the destinition buffer
                                    where result will be placed.
                  * @param evenbuffer specified source buffer with even bytes.
                  * @param offbuffer specified source buffer with odd bytes.
                  * @note           This code assumed that evenbuffer and
                                    oddbuffer have same alignment, but
                                    destbuffer has proportional alignment.
                 **/
__inline static void __FASTCALL__ mmxInterleaveBuffers(tUInt32 limit,
                                    void *destbuffer,
                                    const void *evenbuffer, 
                                    const void *oddbuffer)
{
  register char *destbuffptr;
  register const char *oddptr, *evenptr;
  register tUInt32 freq;
  destbuffptr = (char *)destbuffer;
  evenptr = (const char *)evenbuffer;
  oddptr = (const char *)oddbuffer;
  freq = 0;
  if(limit>REGMM_SIZE*4-1)
  {
      register tUInt32 delta, nlimit;
      /* Try to align buffers on boundary of REGMM_SIZE */
      delta = ((tUInt32)evenptr)&(REGMM_SIZE-1);
      if(delta) delta=REGMM_SIZE-delta;
      nlimit=(limit-delta)/REGMM_SIZE;
      freq+=delta+(nlimit*REGMM_SIZE);
      while(delta)
      {
        *destbuffptr++ = *evenptr++;
        *destbuffptr++ = *oddptr++;
        delta--;
      }
      /* Perform MMX optimized interleaving */
      while(nlimit)
      {
         /* Interleave mmx and cpu instructions */
         __asm("movq	%0,%%mm0"::"m"(*evenptr):"memory");
         evenptr+=REGMM_SIZE;
         __asm("movq	%%mm0, %%mm1\n"
              "	punpckhbw %0, %%mm0\n"::
              "m"(*oddptr):"memory");
         nlimit--;
         __asm("punpcklbw %0, %%mm1"::"m"(*oddptr):"memory");
         oddptr+=REGMM_SIZE;
         __asm("movq	%%mm0, %1\n"
              "	movq	%%mm1, %0":
              "=m"(*destbuffptr),"=m"(destbuffptr[REGMM_SIZE])::"memory");
         destbuffptr+=REGMM_SIZE*2;
      }
      __MMX_EMPTY();
  }
  /* If tail exists then finish it */
  while(freq<limit)
  {
    *destbuffptr++ = *evenptr++;
    *destbuffptr++ = *oddptr++;
    freq++;
  }
}
#define __INTERLEAVE_BUFFERS mmxInterleaveBuffers

                /** Performs conversation string of characters to zero extended
                    string of short values.
                  * @return         none
                  * @param limit    specified size of evenbuffer and oddbuffer
                  * @param destbuffer specified pointer to the destinition buffer
                                    where result will be placed.
                  * @param evenbuffer specified source buffer with even bytes.
                  * @note           This code assumed that destbuffer has
		                    proportional alignment to evenbuffer.
                 **/
__inline static void __FASTCALL__ mmxCharsToShorts(tUInt32 limit,
                                             void *destbuffer,
                                             const void *evenbuffer)
{
  register char *destbuffptr;
  register const char *evenptr;
  register tUInt32 freq;
  destbuffptr = (char *)destbuffer;
  evenptr = (const char *)evenbuffer;
  freq = 0;
  if(limit>REGMM_SIZE*4-1)
  {
      register tUInt32 delta, nlimit;
      /* Try to align buffer on boundary of REGMM_SIZE */
      delta = ((tUInt32)evenptr)&(REGMM_SIZE-1);
      if(delta) delta=REGMM_SIZE-delta;
      nlimit=(limit-delta)/REGMM_SIZE;
      freq+=delta+(nlimit*REGMM_SIZE);
      while(delta)
      {
        *destbuffptr++ = *evenptr++;
        *destbuffptr++ = 0;
        delta--;
      }
      /* Perform MMX optimized loop */
      __asm("pxor	%%mm2, %%mm2":::"memory");
      while(nlimit)
      {
         /* Interleave mmx and cpu instructions */
         __asm("movq	%0,%%mm0"::"m"(*evenptr):"memory");
         evenptr+=REGMM_SIZE;
         __asm("movq	%%mm0, %%mm1\n"
              "	punpckhbw %%mm2, %%mm0\n":::"memory");
         nlimit--;
         __asm("punpcklbw %%mm2, %%mm1":::"memory");
         __asm("movq	%%mm0, %1\n"
              "	movq	%%mm1, %0":
              "=m"(*destbuffptr),"=m"(destbuffptr[REGMM_SIZE])::"memory");
         destbuffptr+=REGMM_SIZE*2;
      }
      __MMX_EMPTY();
  }
  /* If tail exists then finish it */
  while(freq<limit)
  {
    *destbuffptr++ = *evenptr++;
    *destbuffptr++ = 0;
    freq++;
  }
}
#define __CHARS_TO_SHORTS mmxCharsToShorts

                /** Performs conversation string of zero extended short values
                    to string of characters.
                  * @return         none
                  * @param limit    specified size of evenbuffer and oddbuffer
                  * @param destbuffer specified pointer to the destinition buffer
                                    where result will be placed.
                  * @param srcbuffer specified source buffer to be converted.
                  * @note           This code assumed that destbuffer has
                                    proportional alignment to srcbuffer.
                  * @warning        This code is danger but we assume that
                                    'srcbuffer' is consist from interleaving
                                    zeroes and digits. Example: '02030A0B0C'
                 **/
__inline static void __FASTCALL__ mmxShortsToChars(tUInt32 limit,
                                     void * destbuffer, const void * srcbuffer)
{
  register char *destbuffptr;
  register const char *srcptr;
  register tUInt32 freq;
  destbuffptr = (char *)destbuffer;
  srcptr = (const char *)srcbuffer;
  freq = 0;
  if(limit>REGMM_SIZE*4-1)
  {
      tUInt32 delta, nlimit;
      /* Try to align buffers on boundary of REGMM_SIZE */
      delta=((tUInt32)destbuffptr)&(REGMM_SIZE-1);
      if(delta) delta=REGMM_SIZE-delta;
      nlimit=(limit-delta)/REGMM_SIZE;
      freq+=delta+(nlimit*REGMM_SIZE);
      while(delta)
      {
        *destbuffptr++ = *srcptr;
        srcptr+=2;
        delta--;
      }
      /* Perform MMX optimized loop */
      while(nlimit)
      {
         /* Interleave mmx and cpu instructions */
         __asm("movq	%0, %%mm0"::"m"(*srcptr):"memory");
         nlimit--;
         __asm("packuswb %0, %%mm0\n"::"m"(srcptr[REGMM_SIZE]):"memory");
         srcptr+=REGMM_SIZE*2;
         __asm("movq	%%mm0, %0":"=m"(*destbuffptr)::"memory");
         destbuffptr+=REGMM_SIZE;
      }
      __MMX_EMPTY();
  }
  /* If tail exists then finish it */
  while(freq<limit)
  {
    *destbuffptr++ = *srcptr;
    srcptr+=2;
    freq++;
  }
}
#define __SHORTS_TO_CHARS mmxShortsToChars
#endif /* enable mmx */

#endif
#endif
#undef ___INLINES_H
#include "biewlib/sysdep/generic/_inlines.h"

